---
title: "Problem Set 6"
format: html
editor: visual
embed-resources: true
execute:
  error: false
---

GitHub link: <https://github.com/IceCedar/STATS506>

## Stratified Bootstrapping

### a.

```{r}
library(DBI)
library(RSQLite)
library(dplyr)
lahman<-dbConnect(RSQLite::SQLite(),"lahman_1871-2022.sqlite")

fielding<-dbGetQuery(lahman,"SELECT * FROM fielding")

#calculate the average RF for each team
field_RF<-fielding %>% filter(InnOuts != 0) %>%
  mutate(RF=3*(PO+A)/(InnOuts)) 
field_team<-field_RF%>%
  group_by(teamID) %>%
  summarize(average_RF=mean(RF,na.rm=TRUE)) %>%
  ungroup()

field_team
```

### 1. Without any Parallel processing

```{r}
# Function without parallel processing
boot1 <- function(n) {
  # Calculate average RF for each team
  team_avg_rf <- field_RF %>%
    group_by(teamID) %>%
    summarize(average_RF = mean(RF, na.rm = TRUE))
  
  # Initialize a list to store SD estimates for each team
  team_sd_estimates <- list()
  
  # Bootstrap loop for each team
  set.seed(123)
  for (team in unique(field_RF$teamID)) {
    team_data <- field_RF %>% filter(teamID == team)
    boot_sds <- numeric(n)
    
    for (i in 1:n) {
      bootstrap_sample <- sample(team_data$RF, size = nrow(team_data), replace = TRUE)
      boot_sds[i] <- sd(bootstrap_sample, na.rm = TRUE)
    }
    
    # Store the estimated SD for the current team
    team_sd_estimates[[as.character(team)]] <- sd(boot_sds)
  }
  
  # Combine average RF and estimated SD into a data frame
  team_results <- team_avg_rf %>%
    mutate(estimated_sd = unlist(team_sd_estimates))
  
  return(team_results)
}

```

### 2. Using parallel processing

```{r}
library(parallel)

boot2 <- function(n) {
  # Ensure field_RF is a data frame
  if (!is.data.frame(field_RF)) {
    stop("field_RF must be a data frame")
  }
  
  # Check if required columns exist
  if (!all(c("teamID", "RF") %in% colnames(field_RF))) {
    stop("field_RF must contain columns 'teamID' and 'RF'")
  }
  
  # Calculate average RF for each team
  team_avg_rf <- field_RF %>%
    group_by(teamID) %>%
    summarize(average_RF = mean(RF, na.rm = TRUE))
  
  num_cores <- detectCores() / 2
  cl <- makeCluster(num_cores)
  
  # Export necessary objects and libraries to the cluster
  clusterExport(cl, list("field_RF", "n"))
  clusterEvalQ(cl, library(dplyr))  # Load necessary libraries on each worker
  
  # Define the bootstrap function for parallel processing
  bootstrap_function <- function(team, field_RF, n) {
    team_data <- field_RF %>% filter(teamID == team)
    boot_sds <- numeric(n)
    
    for (i in 1:n) {
      bootstrap_sample <- sample(team_data$RF, size = nrow(team_data), replace = TRUE)
      boot_sds[i] <- sd(bootstrap_sample, na.rm = TRUE)
    }
    
    return(sd(boot_sds))
  }
  
  # Run the bootstrap function in parallel using parLapply
  set.seed(123)
  team_sd_estimates <- parLapply(cl, unique(field_RF$teamID), function(team) {
    bootstrap_function(team, field_RF, n)
  })
  
  # Stop the cluster after computation
  stopCluster(cl)
  
  # Combine average RF and estimated SD into a data frame
  team_results <- team_avg_rf %>%
    mutate(estimated_sd = unlist(team_sd_estimates))
  
  return(team_results)
}

```

### 3. Using futures with the future package

```{r}
library(future)
library(future.apply)

boot3 <- function(n) {
  # Set up parallel computation plan
  plan(multisession, workers = 4) 
  options(future.rng.onMisuse = "ignore") 
  
  # Define the bootstrap function for each team
  bootstrap_function <- function(team, field_RF, n) {
    team_data <- field_RF %>% filter(teamID == team)
    boot_sds <- numeric(n)
    
    for (i in 1:n) {
      bootstrap_sample <- sample(team_data$RF, size = nrow(team_data), replace = TRUE)
      boot_sds[i] <- sd(bootstrap_sample, na.rm = TRUE)
    }
    
    return(sd(boot_sds))
  }
  
  # Run the bootstrap function in parallel using future_lapply
  set.seed(123)
  team_sd_estimates <- future_lapply(unique(field_RF$teamID), bootstrap_function, field_RF = field_RF, n = n)
  
  # Calculate average RF for each team
  team_avg_rf <- field_RF %>%
    group_by(teamID) %>%
    summarize(average_RF = mean(RF, na.rm = TRUE))
  
  # Combine average RF and estimated SD into a data frame
  team_results <- team_avg_rf %>%
    mutate(estimated_sd = unlist(team_sd_estimates))
  
  return(team_results)
}

```

### b.

### 1. Without any Parallel processing

```{r}
field_team1<-boot1(1000)
field_team1 %>%
  arrange(desc(average_RF)) %>%  # Order by average_RF
  head(10)

```

### 2. Using parallel processing

```{r}
field_team2<-boot2(1000)
field_team2 %>%
  arrange(desc(average_RF)) %>%  # Order by average_RF
  head(10)
```

### 3. Using futures with the future package

```{r}
field_team3<-boot3(1000)
field_team3 %>%
  arrange(desc(average_RF)) %>%  # Order by average_RF
  head(10)
```

### c.

```{r}
basic<-system.time({
  boot1(1000)  # Without any parallel processing
})

Parrallel<-system.time({
  boot2(1000)  # Using parallel processing
})

Future<-system.time({
  boot3(1000)  # Using futures with the future package
})

rbind(basic,Parrallel,Future)
```

```{r}
#Compare different sample size
basic<-system.time({
  boot1(100)  # Without any parallel processing
})

Parrallel<-system.time({
  boot2(100)  # Using parallel processing
})

Future<-system.time({
  boot3(100)  # Using futures with the future package
})

rbind(basic,Parrallel,Future)
```

The basic method demonstrates good performance with small sample sizes; however, it becomes inefficient for larger datasets due to its single-threaded nature. While employing parallel processing and futures, the efficiency gains are minimal for smaller sample size. In contrast, when handling larger sample sizes, the advantages of both parallelization and futures become pronounced. These methods significantly reduce computation time and improve resource utilization compared to the basic method, making them more suitable for large-scale data analysis. Overall, the choice of method should consider the sample size, as parallel processing and futures are more effective in scenarios involving larger datasets.
